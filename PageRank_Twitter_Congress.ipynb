{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["# PageRank Implementation on Twitter Congress Dataset\n", "This notebook implements the PageRank algorithm from scratch under both unweighted and weighted edge settings."]}, {"cell_type": "markdown", "metadata": {}, "source": ["## \ud83d\udcc4 Code Documentation (Simple & Humanized)\n", "\n", "### \ud83d\udd38 What This Code Does\n", "This code implements the **PageRank algorithm** from scratch. It calculates how \u201cimportant\u201d each person (node) is in a Twitter network of U.S. Congress members based on how they are connected.\n", "\n", "We use two versions of PageRank:\n", "1. **Unweighted PageRank**: All connections are treated equally.\n", "2. **Weighted PageRank**: Some connections are stronger than others (e.g., more retweets or replies), so they pass more influence.\n", "\n", "---\n", "\n", "### \ud83d\udd38 How the Graph Is Represented\n", "We represent the Twitter network as a **directed graph**, which means each connection goes from one person to another.\n", "\n", "We use two dictionaries:\n", "- `adjacency`: tells us who each person is connected to (i.e., who they follow or interact with).\n", "- `weights`: tells us how strong each connection is. For example, if user A has 3 connections and one is stronger than the others, that one gets more influence in weighted PageRank.\n", "\n", "Both dictionaries are built using a function called `load_graph()`, which reads the file and stores the data in a way that\u2019s easy to use later.\n", "\n", "---\n", "\n", "### \ud83d\udd38 What Is PageRank Doing?\n", "Think of each node (person) starting with the same amount of \"influence.\" At every step, they give away their influence to others they are connected to.\n", "\n", "- In **unweighted**, it\u2019s shared equally among all connections.\n", "- In **weighted**, it\u2019s shared based on how strong each connection is.\n", "\n", "We repeat this process multiple times until the scores stop changing much \u2014 that\u2019s when we say the algorithm has **converged**.\n", "\n", "---\n", "\n", "### \ud83d\udd38 Stopping Condition (When to Stop Iterating)\n", "We stop when one of these happens:\n", "- The scores don\u2019t change much anymore (difference is less than `1e-6`).\n", "- We hit the maximum number of steps (default is 100 iterations).\n", "\n", "This helps avoid running forever and ensures the result is stable.\n", "\n", "---\n", "\n", "### \ud83d\udd38 What the Output Shows\n", "At the end, we display the **top 25 people with the highest PageRank score** for both unweighted and weighted versions.\n", "\n", "This tells us who is the most influential in the network based on connections \u2014 either treating all connections the same, or taking connection strength into account."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from collections import defaultdict\n", "import pandas as pd\n", "\n", "def load_graph(file_path):\n", "    adjacency = defaultdict(list)\n", "    weights = defaultdict(lambda: defaultdict(float))\n", "\n", "    with open(file_path, 'r') as f:\n", "        for line in f:\n", "            src, dst = line.strip().split()\n", "            adjacency[src].append(dst)\n", "            weights[src][dst] += 1.0\n", "\n", "    return adjacency, weights\n", "\n", "def pagerank_unweighted(graph, damping=0.85, max_iter=100, tol=1e-6):\n", "    nodes = set(graph.keys())\n", "    for targets in graph.values():\n", "        nodes.update(targets)\n", "    nodes = list(nodes)\n", "    N = len(nodes)\n", "    pr = {node: 1.0 / N for node in nodes}\n", "\n", "    for _ in range(max_iter):\n", "        new_pr = {node: (1 - damping) / N for node in nodes}\n", "        for node in nodes:\n", "            out_links = graph.get(node, [])\n", "            if not out_links:\n", "                continue\n", "            share = pr[node] / len(out_links)\n", "            for neighbor in out_links:\n", "                new_pr[neighbor] += damping * share\n", "        if all(abs(new_pr[n] - pr[n]) < tol for n in nodes):\n", "            break\n", "        pr = new_pr\n", "    return pr\n", "\n", "def pagerank_weighted(graph, weights, damping=0.85, max_iter=100, tol=1e-6):\n", "    nodes = set(graph.keys())\n", "    for targets in graph.values():\n", "        nodes.update(targets)\n", "    nodes = list(nodes)\n", "    N = len(nodes)\n", "    pr = {node: 1.0 / N for node in nodes}\n", "\n", "    for _ in range(max_iter):\n", "        new_pr = {node: (1 - damping) / N for node in nodes}\n", "        for node in nodes:\n", "            neighbors = graph.get(node, [])\n", "            total_weight = sum(weights[node].values())\n", "            if total_weight == 0:\n", "                continue\n", "            for neighbor in neighbors:\n", "                weight = weights[node][neighbor]\n", "                new_pr[neighbor] += damping * pr[node] * (weight / total_weight)\n", "        if all(abs(new_pr[n] - pr[n]) < tol for n in nodes):\n", "            break\n", "        pr = new_pr\n", "    return pr\n", "\n", "def top_k(pr_dict, k=25):\n", "    return sorted(pr_dict.items(), key=lambda x: x[1], reverse=True)[:k]"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Load the dataset\n", "adjacency, weights = load_graph('congress.edges')"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Run unweighted PageRank\n", "unweighted_pr = pagerank_unweighted(adjacency)\n", "top_25_unweighted = top_k(unweighted_pr)\n", "pd.DataFrame(top_25_unweighted, columns=[\"Node\", \"Unweighted PR\"])"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Run weighted PageRank\n", "weighted_pr = pagerank_weighted(adjacency, weights)\n", "top_25_weighted = top_k(weighted_pr)\n", "pd.DataFrame(top_25_weighted, columns=[\"Node\", \"Weighted PR\"])"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Comparison of Top 25\n", "df_unweighted = pd.DataFrame(top_25_unweighted, columns=[\"Node\", \"Unweighted PR\"])\n", "df_weighted = pd.DataFrame(top_25_weighted, columns=[\"Node\", \"Weighted PR\"])\n", "comparison = pd.merge(df_unweighted, df_weighted, on=\"Node\", how=\"outer\")\n", "comparison"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"name": "python", "version": "3.x"}}, "nbformat": 4, "nbformat_minor": 2}